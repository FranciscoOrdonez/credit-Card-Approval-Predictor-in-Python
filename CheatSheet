1. # Load dataset
   cc_apps = pd.read_csv("datasets/cc_approvals.data" , header=None)
   
2. # Print summary statistics
   print(cc_apps.describe())
   
3. # Print DataFrame information
   print(cc_apps.info())
   
4. # inspect last 17 rows of dataframe
   print(cc_apps.tail(17))
   
5. # Replace the '?'s with NaN
   cc_apps[cc_apps == '?'] = np.NaN
   
6. #count number of NaNs in the dataset prior of using mean imputation
   print(cc_apps.isnull().sum())
   
7. # Impute the missing values with mean imputation
   cc_apps.fillna(cc_apps.mean(), inplace=True)
   
8. # Impute the missing values for non numeric columns with the most frequent value of column
   for col in cc_apps.columns:
      # Check if the column is of object type
      if cc_apps[col].dtype == 'object':
          cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])
          
9. # convert non numeric columns into numeric
   from sklearn.preprocessing import LabelEncoder
   le = LabelEncoder()
   for col in cc_apps.columns.values:
      # Compare if the dtype is object
      if cc_apps[col].dtypes=='object':
        # Use LabelEncoder to do the numeric transformation
        cc_apps[col]=le.fit_transform(cc_apps[col])  
        
10. # Drop the features 11 and 13 
   cc_apps = cc_apps.drop([11, 13], axis=1)
   
11. #change cc_apps pandas framework to a numpy array
   cc_apps = cc_apps.values
   
12. # Segregate features and labels into separate variables
   X,y = cc_apps[:,0:12] , cc_apps[:,13]
   
13. #separate data into train and test sets
   from sklearn.model_selection import train_test_split
   X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)
   
14. # scaling the data
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler(feature_range=(0, 1))
    rescaledX_train = scaler.fit_transform(X_train)
    rescaledX_test = scaler.fit_transform(X_test)   
    
15. #LogisticRegression
    from sklearn.linear_model import LogisticRegression
    logreg = LogisticRegression()
    logreg.fit(rescaledX_train, y_train) 
    
16. # Use logreg to predict instances from the test set and store it
    y_pred = logreg.predict(rescaledX_test)    
    
17.  # Get the accuracy score of logreg model and print it
    from sklearn.metrics import accuracy_score
    print("Accuracy of logistic regression classifier: ", accuracy_score(y_test,y_pred))
    
18. # print confusion matrix of the logreg model
    from sklearn.metrics import confusion_matrix
    print(confusion_matrix(y_test,y_pred))
    
19. # print classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test,y_pred))
    
20.  # grid model
    from sklearn.model_selection import GridSearchCV

    # Define the grid of values for tol and max_iter
    tol = [0.01,0.001,0.0001]
    max_iter = [100,150,200]

    # Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values
    param_grid = dict(tol = tol, max_iter = max_iter)

    # Instantiate GridSearchCV with the required parameters
    grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)

    # Use scaler to rescale X and assign it to rescaledX
    rescaledX = scaler.fit_transform(X)

    # Fit data to grid_model
    grid_model_result = grid_model.fit(rescaledX, y)

    # Summarize results
    best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_
    print("Best: %f using %s" % (best_score, best_params))   
